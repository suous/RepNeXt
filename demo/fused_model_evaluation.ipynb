{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/suous/RepNeXt/releases/download/v1.0/repnext_m1_distill_300e_fused.pt -P checkpoint"
      ],
      "metadata": {
        "id": "eRLthOPV1EHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ImageNet-1K Evaluation"
      ],
      "metadata": {
        "id": "y2mtjsb7d8J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# refer to: https://github.com/pytorch/examples/blob/main/imagenet/extract_ILSVRC.sh\n",
        "## 1. Download the val data\n",
        "#  ILSVRC2012_img_val.tar (about 6.3 GB). MD5: 29b22e2961454d5413ddabcf34fc5622\n",
        "wget -cq https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar -P imagenet/val\n",
        "\n",
        "## 2. Change directory; extract validation .tar; remove compressed file\n",
        "cd imagenet/val && tar -xf ILSVRC2012_img_val.tar && rm -f ILSVRC2012_img_val.tar\n",
        "\n",
        "## 3. Get script from soumith and run; this script creates all class directories and moves images into corresponding directories\n",
        "wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash\n",
        "#\n",
        "# This results in a validation directory like so:\n",
        "#\n",
        "#  imagenet/val/\n",
        "#  ├── n01440764\n",
        "#  │   ├── ILSVRC2012_val_00000293.JPEG\n",
        "#  │   ├── ILSVRC2012_val_00002138.JPEG\n",
        "#  │   ├── ......\n",
        "#  ├── ......\n",
        "#\n",
        "\n",
        "## 4. Change back to original directory\n",
        "cd ../..\n",
        "\n",
        "## 5. Check total files after extract\n",
        "find imagenet/val/ -name \"*.JPEG\" | wc -l\n",
        "#  50000"
      ],
      "metadata": {
        "id": "WppgHXp8b5KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation Functions\n",
        "\n",
        "import io\n",
        "import os\n",
        "import time\n",
        "from collections import defaultdict, deque\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets.folder import ImageFolder\n",
        "\n",
        "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
        "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    maxk = min(max(topk), output.size()[1])\n",
        "    batch_size = target.size(0)\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.reshape(1, -1).expand_as(pred))\n",
        "    return [correct[:min(k, maxk)].reshape(-1).float().sum(0) * 100. / batch_size for k in topk]\n",
        "\n",
        "\n",
        "class SmoothedValue(object):\n",
        "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
        "    window or the global series average.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, window_size=20, fmt=None):\n",
        "        if fmt is None:\n",
        "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
        "        self.deque = deque(maxlen=window_size)\n",
        "        self.total = 0.0\n",
        "        self.count = 0\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.deque.append(value)\n",
        "        self.count += n\n",
        "        self.total += value * n\n",
        "\n",
        "    @property\n",
        "    def median(self):\n",
        "        d = torch.tensor(list(self.deque))\n",
        "        return d.median().item()\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
        "        return d.mean().item()\n",
        "\n",
        "    @property\n",
        "    def global_avg(self):\n",
        "        return self.total / self.count\n",
        "\n",
        "    @property\n",
        "    def max(self):\n",
        "        return max(self.deque)\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        return self.deque[-1]\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.fmt.format(\n",
        "            median=self.median,\n",
        "            avg=self.avg,\n",
        "            global_avg=self.global_avg,\n",
        "            max=self.max,\n",
        "            value=self.value)\n",
        "\n",
        "\n",
        "class MetricLogger(object):\n",
        "    def __init__(self, delimiter=\"\\t\"):\n",
        "        self.meters = defaultdict(SmoothedValue)\n",
        "        self.delimiter = delimiter\n",
        "\n",
        "    def update(self, **kwargs):\n",
        "        for k, v in kwargs.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                v = v.item()\n",
        "            assert isinstance(v, (float, int))\n",
        "            self.meters[k].update(v)\n",
        "\n",
        "    def __getattr__(self, attr):\n",
        "        if attr in self.meters:\n",
        "            return self.meters[attr]\n",
        "        if attr in self.__dict__:\n",
        "            return self.__dict__[attr]\n",
        "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
        "            type(self).__name__, attr))\n",
        "\n",
        "    def __str__(self):\n",
        "        loss_str = []\n",
        "        for name, meter in self.meters.items():\n",
        "            loss_str.append(\n",
        "                \"{}: {}\".format(name, str(meter))\n",
        "            )\n",
        "        return self.delimiter.join(loss_str)\n",
        "\n",
        "    def add_meter(self, name, meter):\n",
        "        self.meters[name] = meter\n",
        "\n",
        "    def log_every(self, iterable, print_freq, header=None):\n",
        "        i = 0\n",
        "        if not header:\n",
        "            header = ''\n",
        "        start_time = time.time()\n",
        "        end = time.time()\n",
        "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
        "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
        "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
        "        log_msg = [\n",
        "            header,\n",
        "            '[{0' + space_fmt + '}/{1}]',\n",
        "            'eta: {eta}',\n",
        "            '{meters}',\n",
        "            'time: {time}',\n",
        "            'data: {data}'\n",
        "        ]\n",
        "        if torch.cuda.is_available():\n",
        "            log_msg.append('max mem: {memory:.0f}')\n",
        "        log_msg = self.delimiter.join(log_msg)\n",
        "        MB = 1024.0 * 1024.0\n",
        "        for obj in iterable:\n",
        "            data_time.update(time.time() - end)\n",
        "            yield obj\n",
        "            iter_time.update(time.time() - end)\n",
        "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
        "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
        "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
        "                if torch.cuda.is_available():\n",
        "                    print(log_msg.format(\n",
        "                        i, len(iterable), eta=eta_string,\n",
        "                        meters=str(self),\n",
        "                        time=str(iter_time), data=str(data_time),\n",
        "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
        "                else:\n",
        "                    print(log_msg.format(\n",
        "                        i, len(iterable), eta=eta_string,\n",
        "                        meters=str(self),\n",
        "                        time=str(iter_time), data=str(data_time)))\n",
        "            i += 1\n",
        "            end = time.time()\n",
        "        total_time = time.time() - start_time\n",
        "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
        "            header, total_time_str, total_time / len(iterable)))\n",
        "\n",
        "\n",
        "def build_dataset(args):\n",
        "    transform = build_transform(args)\n",
        "    root = os.path.join(args.data_path, 'val')\n",
        "    dataset = datasets.ImageFolder(root, transform=transform)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def build_transform(args):\n",
        "    resize_im = args.input_size > 32\n",
        "    t = []\n",
        "    if resize_im:\n",
        "        size = int((256 / 224) * args.input_size)\n",
        "        t.append(\n",
        "            # to maintain same ratio w.r.t. 224 images\n",
        "            transforms.Resize(size, interpolation=3),\n",
        "        )\n",
        "        t.append(transforms.CenterCrop(args.input_size))\n",
        "\n",
        "    t.append(transforms.ToTensor())\n",
        "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
        "    return transforms.Compose(t)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(data_loader, model, device):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = 'Test:'\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    for images, target in metric_logger.log_every(data_loader, 10, header):\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        # compute output\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "        batch_size = images.shape[0]\n",
        "        metric_logger.update(loss=loss.item())\n",
        "        metric_logger.meters['acc1'].update(acc1.item(), n=batch_size)\n",
        "        metric_logger.meters['acc5'].update(acc5.item(), n=batch_size)\n",
        "    print('* Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f} loss {losses.global_avg:.3f}'\n",
        "          .format(top1=metric_logger.acc1, top5=metric_logger.acc5, losses=metric_logger.loss))\n",
        "\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
      ],
      "metadata": {
        "id": "norejYDKeQAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "args = Namespace(\n",
        "    device=\"cuda\",\n",
        "    model=\"repnext_m1\",\n",
        "    batch_size=256,\n",
        "    input_size=224,\n",
        "    num_workers=4,\n",
        "    model_path=\"checkpoint/repnext_m1_distill_300e_fused.pt\",\n",
        "    data_path=\"imagenet\",\n",
        ")\n",
        "\n",
        "device = torch.device(args.device)\n",
        "dataset_val = build_dataset(args=args)\n",
        "sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
        "data_loader_val = torch.utils.data.DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=sampler_val,\n",
        "    batch_size=int(1.5 * args.batch_size),\n",
        "    num_workers=args.num_workers,\n",
        "    pin_memory=True,\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "print(\"Loading local checkpoint at {}\".format(args.model_path))\n",
        "model = torch.jit.load(args.model_path, map_location='cpu')\n",
        "\n",
        "model.to(device)\n",
        "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('number of params:', n_parameters)\n",
        "print(f\"Evaluating model: {args.model}\")\n",
        "test_stats = evaluate(data_loader_val, model, device)\n",
        "print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")"
      ],
      "metadata": {
        "id": "eN2as1MHj3nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)"
      ],
      "metadata": {
        "id": "tremoddSdzWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "metadata": {
        "id": "LIcO29LQ4gLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load(args.model_path)\n",
        "inputs = torch.randn(5, 3, 224, 224)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "QXp0SiJ3HPia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load(args.model_path).cuda()\n",
        "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "n2KJ2vf4YwCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load(args.model_path)\n",
        "inputs = torch.randn(5, 3, 224, 224)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU], profile_memory=True, record_shapes=True) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "id": "8xmJj3osZOhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load(args.model_path).cuda()\n",
        "inputs = torch.randn(5, 3, 224, 224).cuda()\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
        "    model(inputs)\n",
        "\n",
        "prof.export_chrome_trace(\"trace.json\")"
      ],
      "metadata": {
        "id": "zZCbuc5DZs23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}